{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_data_collector import get_files\n",
    "from custom_data_collector import SimpleSplitDataSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_files = get_files(\n",
    "    dir='../data/SDF-JEPA-main', \n",
    "    extension='.py', \n",
    "    filter_regex=r'^(?!import\\b).*\\S.*$',\n",
    "    min_lines=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SimpleSplitDataSampler(\n",
    "    py_files, \n",
    "    300,\n",
    "    300,\n",
    "    300,\n",
    "    splitters=['.', ',', '(', ')', ' '],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sampler.sample(20, strategy='finish_line', strategy_kwargs={'max_tries': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename        ../data/SDF-JEPA-main/app/main_distributed.py\n",
       "prefix      # Copyright (c) Meta Platforms, Inc. and affil...\n",
       "middle      (\\n    help='yaml file containing config file ...\n",
       "suffix          default='configs.yaml')\\nparser.add_argume...\n",
       "meta                                              finish_line\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "num_examples = 350\n",
    "splitters = ['.', ',', '(', ')', ' ']\n",
    "pattern = '|'.join(map(re.escape, splitters))\n",
    "\n",
    "dataset = {\n",
    "    'filename': np.random.choice(py_files, num_examples, replace=False),\n",
    "    'prefix': [],\n",
    "    'middle': [],\n",
    "    'suffix': [],\n",
    "}\n",
    "\n",
    "for filename in dataset['filename']:\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    matches = []\n",
    "    while len(matches) == 0:\n",
    "        cursor_line = np.random.randint(len(lines) - 2)\n",
    "        matches = [match.start() for match in re.finditer(pattern, lines[cursor_line])]\n",
    "\n",
    "    cursor_pos = np.random.choice(matches, 1)[0]\n",
    "\n",
    "    prefix = ''.join(lines[:cursor_line + 1]) + lines[cursor_line][:cursor_pos]\n",
    "    middle = lines[cursor_line][cursor_pos:] + lines[cursor_line + 1]\n",
    "    suffix = ''.join(lines[cursor_line + 2:])\n",
    "\n",
    "    dataset['prefix'].append(prefix)\n",
    "    dataset['middle'].append(middle)\n",
    "    dataset['suffix'].append(suffix)\n",
    "\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# pip install -q transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = 'bigcode/tiny_starcoder_py'\n",
    "device = 'cuda' # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prefix_len = 300\n",
    "max_suffix_len = 300\n",
    "max_middle_len = 100\n",
    "\n",
    "dataset['query'] = (\n",
    "    '<fim_prefix>' + dataset['prefix'].str[-max_prefix_len:] + \n",
    "    '<fim_suffix>' + dataset['suffix'].str[:max_suffix_len] + \n",
    "    '<fim_middle>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>',\n",
       " '<fim_prefix>',\n",
       " '<fim_middle>',\n",
       " '<fim_suffix>',\n",
       " '<fim_pad>',\n",
       " '<filename>',\n",
       " '<gh_stars>',\n",
       " '<issue_start>',\n",
       " '<issue_comment>',\n",
       " '<issue_closed>',\n",
       " '<jupyter_start>',\n",
       " '<jupyter_text>',\n",
       " '<jupyter_code>',\n",
       " '<jupyter_output>',\n",
       " '<empty_output>',\n",
       " '<commit_before>',\n",
       " '<commit_msg>',\n",
       " '<commit_after>',\n",
       " '<reponame>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "inputs, masks = tokenizer(dataset['query'].to_list(), padding=True, return_tensors='pt').values()\n",
    "inputs = inputs.to(device)\n",
    "masks = masks.to(device)\n",
    "\n",
    "outputs = model.generate(inputs, attention_mask=masks, max_length=max_prefix_len + max_suffix_len + max_middle_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,    81,  1172,    81],\n",
       "        [    0,     0,     0,  ...,   347,    35,  6935],\n",
       "        ...,\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,   645, 12643,    32],\n",
       "        [    0,     0,     0,  ...,   280,   313,  2958]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_text[0].find('<fim_middle>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fim_prefix>from itertools import product\n",
      "from string import ascii_lowercase\n",
      "\n",
      "import numpy as np\n",
      "import pytest\n",
      "\n",
      "from pandas import (\n",
      "from pandas import <fim_suffix>    Index,\n",
      "    MultiIndex,\n",
      "    Period,\n",
      "    Series,\n",
      "    Timedelta,\n",
      "    Timestamp,\n",
      "    date_range,\n",
      ")\n",
      "import pandas._testing as tm\n",
      "\n",
      "\n",
      "class TestCounting:\n",
      "    def test_cumcount(self):\n",
      "        df = DataFrame([[\"a\"], [\"a\"], [\"a\"], [\"b\"], [\"a\"]], columns=[\"A\"])\n",
      "        g = df.groupby(\"A\")\n",
      "        sg = g.A\n",
      "\n",
      "<fim_middle>\n"
     ]
    }
   ],
   "source": [
    "print(dataset['query'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from itertools import product\n",
      "from string import ascii_lowercase\n",
      "\n",
      "import numpy as np\n",
      "import pytest\n",
      "\n",
      "from pandas import (\n",
      "from pandas import     Index,\n",
      "    MultiIndex,\n",
      "    Period,\n",
      "    Series,\n",
      "    Timedelta,\n",
      "    Timestamp,\n",
      "    date_range,\n",
      ")\n",
      "import pandas._testing as tm\n",
      "\n",
      "\n",
      "class TestCounting:\n",
      "    def test_cumcount(self):\n",
      "        df = DataFrame([[\"a\"], [\"a\"], [\"a\"], [\"b\"], [\"a\"]], columns=[\"A\"])\n",
      "        g = df.groupby(\"A\")\n",
      "        sg = g.A\n",
      "\n",
      "DataFrame,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(outputs_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
